Asm_Kernel
==========

Assembler 64 bit multi process, multi thread kernel.

Runs on OSX or Linux. Could move to bare metal eventually but it's useful for
now to run hosted while experimenting.

Uses a virtual cpu instruction macro set to avoid use of x64 native
instructions. It will eventual run on ARM Linux for machines such as Raspberry
PI and BeagleBone with no source modification.

Has function level dynamic binding and loading. Individual functions are loaded
and bound on demand as tasks are created and distributed. Currently functions
are loaded from the cpu file system on which the task finds itself, but these
will eventually come from the server object that the task was created with and
functions will be transported across the network as required. Functions are
shared between all tasks that share the same server object, so only a single
copy of a function is loaded regardless of how many tasks use that function.

There is a powerful object and class system, not just for an assembler, but
quite as capable as a high level language. Static classes or virtual classes
with virtual, nonvirtual and overridable methods can be defined. Calls are type
checked to ensure consistency across the class hierarchy. The GUI is constructed
using this class system.

The interface to the system functions is provided as a set of static classes,
easing use and removing the need to remember static function locations, plus
decoupling the source from changes at the system level. Look in the inc/
directory to see the interface definitions.

Allows modelling of various network topologies with point to point links. Each
cpu in the network is modelled as a separate host process, point to point links
use shared memory to simulate cpu to cpu, point to point, bi directional
connections. There is no global bus based networking on purpose.

Network link routing tables are created on booting a link, and the process is
distributed in nature, each link starts a flood fill that eventually reaches all
the cpus and along the way has marked all the routes from one cpu to another.
All shortest routes are found, messages going off cpu are assigned to a link as
the link becomes free and multiple links can and do route messages over parallel
routes simultaneously.

The -run command line option launches tasks on booting that cpu, such as the
test suit or experimental GUI (a work in progress, -run gui/gui).

The -l command line option creates a link, currently up to 1000 cpu's are
allowed but that is easy to adjust in the sys/link.nasm file and is due to the
very simple link parameter parsing. The lower numbered cpu always comes first !
The shared memory link files are created in /tmp, so for example /tmp/000-001
would be the link file for the link between cpu 000 and 001.

The -cpu command line option just labels the cpu with it's ID.

An example network viewed with ps looks like this for a 4x4 mesh network:

./main -cpu 15 -l 011-015 -l 003-015 -l 014-015 -l 012-015
./main -cpu 14 -l 010-014 -l 002-014 -l 013-014 -l 014-015
./main -cpu 13 -l 009-013 -l 001-013 -l 012-013 -l 013-014
./main -cpu 12 -l 008-012 -l 000-012 -l 012-015 -l 012-013
./main -cpu 11 -l 007-011 -l 011-015 -l 010-011 -l 008-011
./main -cpu 10 -l 006-010 -l 010-014 -l 009-010 -l 010-011
./main -cpu 9 -l 005-009 -l 009-013 -l 008-009 -l 009-010
./main -cpu 8 -l 004-008 -l 008-012 -l 008-011 -l 008-009
./main -cpu 7 -l 003-007 -l 007-011 -l 006-007 -l 004-007
./main -cpu 6 -l 002-006 -l 006-010 -l 005-006 -l 006-007
./main -cpu 5 -l 001-005 -l 005-009 -l 004-005 -l 005-006
./main -cpu 4 -l 000-004 -l 004-008 -l 004-007 -l 004-005
./main -cpu 3 -l 003-015 -l 003-007 -l 002-003 -l 000-003
./main -cpu 2 -l 002-014 -l 002-006 -l 001-002 -l 002-003
./main -cpu 1 -l 001-013 -l 001-005 -l 000-001 -l 001-002
./main -cpu 0 -l 000-012 -l 000-004 -l 000-003 -l 000-001 -run gui/gui

Make with:

make -j

Requires NASM, SDL2 and the SDL2_ttf library to be installed. SDL2 and SDL2_ttf
are for the experimental gui.

Run with:

./run.sh <num_cpus>

Fully connected network. Each cpu has links to every other cpu. Careful with
this as you can end up with a very large number of link files and shared memory
regions.

./run_star.sh <num_cpus>

Star connected network. Each cpu has a link to the first cpu.

./run_ring.sh <num_cpus>

Ring connected network. Each cpu has links to the next and previous cpus.

./run_tree.sh <num_cpus>

Tree connected network. Each cpu has links to its parent cpu and up to two
child cpus.

./run_mesh.sh <num_cpus on a side>

Mesh connected network. Each cpu has links to 4 adjacent cpus. This is similar
to Transputer meshes.

./run_cube.sh <num_cpus on a side>

Cube connected network. Each cpu has links to 6 adjacent cpus. This is similar
to TMS320C40 meshes.

Stop with:

./stop.sh
